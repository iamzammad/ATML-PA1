{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers torch torchvision","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-23T08:34:17.108609Z","iopub.execute_input":"2024-09-23T08:34:17.109710Z","iopub.status.idle":"2024-09-23T08:34:29.908820Z","shell.execute_reply.started":"2024-09-23T08:34:17.109663Z","shell.execute_reply":"2024-09-23T08:34:29.907722Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.0)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.19.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.24.6)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.4)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torchvision import datasets, transforms\nfrom transformers import CLIPProcessor, CLIPModel\nimport torch.nn.functional as F\nfrom tqdm.notebook import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-09-23T08:34:29.910630Z","iopub.execute_input":"2024-09-23T08:34:29.911578Z","iopub.status.idle":"2024-09-23T08:34:29.917252Z","shell.execute_reply.started":"2024-09-23T08:34:29.911527Z","shell.execute_reply":"2024-09-23T08:34:29.916085Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224, 224)),  \n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\ntrain_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\ntest_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-23T08:34:29.918358Z","iopub.execute_input":"2024-09-23T08:34:29.918666Z","iopub.status.idle":"2024-09-23T08:34:31.530263Z","shell.execute_reply.started":"2024-09-23T08:34:29.918634Z","shell.execute_reply":"2024-09-23T08:34:31.529493Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\nprocessor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")","metadata":{"execution":{"iopub.status.busy":"2024-09-23T08:34:31.531342Z","iopub.execute_input":"2024-09-23T08:34:31.531621Z","iopub.status.idle":"2024-09-23T08:34:32.873648Z","shell.execute_reply.started":"2024-09-23T08:34:31.531591Z","shell.execute_reply":"2024-09-23T08:34:32.872795Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"cifar_classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n\ndef evaluate(model, dataloader):\n    model.eval()\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        for images, labels in tqdm(dataloader):\n            images, labels = images.to(device), labels.to(device)\n\n            image_features = model.get_image_features(images)\n            image_features = F.normalize(image_features, p=2, dim=-1)\n\n            text_inputs = processor(text=cifar_classes, return_tensors=\"pt\", padding=True).to(device)\n            text_features = model.get_text_features(**text_inputs)\n            text_features = F.normalize(text_features, p=2, dim=-1)\n\n            similarity = torch.matmul(image_features, text_features.T)\n\n            predictions = similarity.argmax(dim=1)\n\n            correct += (predictions == labels).sum().item()\n            total += labels.size(0)\n\n    return correct / total\n\naccuracy = evaluate(model, test_loader)\nprint(f\"Test Accuracy: {accuracy:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-23T08:34:32.876084Z","iopub.execute_input":"2024-09-23T08:34:32.876492Z","iopub.status.idle":"2024-09-23T08:35:03.797147Z","shell.execute_reply.started":"2024-09-23T08:34:32.876457Z","shell.execute_reply":"2024-09-23T08:35:03.796145Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73f37eaba31a4937ac5bf47232d9aba0"}},"metadata":{}},{"name":"stdout","text":"Test Accuracy: 0.8242\n","output_type":"stream"}]}]}