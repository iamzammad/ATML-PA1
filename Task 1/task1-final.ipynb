{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9503961,"sourceType":"datasetVersion","datasetId":5784356},{"sourceId":9516233,"sourceType":"datasetVersion","datasetId":5793389}],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Necessary Imports and Installations","metadata":{}},{"cell_type":"code","source":"!pip install diffusers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-30T12:20:42.956050Z","iopub.execute_input":"2024-09-30T12:20:42.956909Z","iopub.status.idle":"2024-09-30T12:20:58.085257Z","shell.execute_reply.started":"2024-09-30T12:20:42.956866Z","shell.execute_reply":"2024-09-30T12:20:58.084289Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting diffusers\n  Downloading diffusers-0.30.3-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.10/site-packages (from diffusers) (7.0.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from diffusers) (3.15.1)\nRequirement already satisfied: huggingface-hub>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from diffusers) (0.25.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from diffusers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from diffusers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from diffusers) (2.32.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from diffusers) (0.4.5)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from diffusers) (10.3.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.2->diffusers) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.2->diffusers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.2->diffusers) (6.0.2)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.2->diffusers) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.2->diffusers) (4.12.2)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata->diffusers) (3.19.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers) (2024.8.30)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.23.2->diffusers) (3.1.2)\nDownloading diffusers-0.30.3-py3-none-any.whl (2.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: diffusers\nSuccessfully installed diffusers-0.30.3\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport numpy as np\nfrom diffusers import StableDiffusionPipeline\nfrom scipy.stats import ttest_rel\nfrom torchvision import transforms\nfrom PIL import Image\n","metadata":{"execution":{"iopub.status.busy":"2024-09-30T12:20:58.087337Z","iopub.execute_input":"2024-09-30T12:20:58.087738Z","iopub.status.idle":"2024-09-30T12:21:17.447401Z","shell.execute_reply.started":"2024-09-30T12:20:58.087700Z","shell.execute_reply":"2024-09-30T12:21:17.446513Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1edadb8552a14a3c84b48b5009aa5119"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Image Preprocessing","metadata":{}},{"cell_type":"code","source":"def read_image(image_path):\n    image = Image.open(image_path).convert(\"RGB\")\n    return image\n\ndef preprocess(image, device):\n    transform_pipeline = transforms.Compose([\n        transforms.Resize((512, 512)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.5], [0.5])  \n    ])\n    \n    processed_image = transform_pipeline(image).unsqueeze(0).to(device, dtype=torch.float16)  \n    return processed_image\n\ndef convert2latent(processed_image, pipeline, device):\n    encoded_image = pipeline.vae.encode(processed_image).latent_dist.mean\n    scaling = pipeline.vae.config.scaling_factor  \n    with torch.no_grad():\n        latents = encoded_image * scaling\n    return latents","metadata":{"execution":{"iopub.status.busy":"2024-09-30T12:21:17.448672Z","iopub.execute_input":"2024-09-30T12:21:17.449253Z","iopub.status.idle":"2024-09-30T12:21:17.457097Z","shell.execute_reply.started":"2024-09-30T12:21:17.449217Z","shell.execute_reply":"2024-09-30T12:21:17.455916Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Forward Diffusion","metadata":{}},{"cell_type":"code","source":"def forward(latents, timestep, scheduler):\n    noise = torch.randn_like(latents)\n    \n    noised = scheduler.add_noise(\n        latents, \n        noise, \n        torch.tensor([timestep], device=latents.device)\n    )\n    \n    return noised","metadata":{"execution":{"iopub.status.busy":"2024-09-30T12:21:17.460013Z","iopub.execute_input":"2024-09-30T12:21:17.460455Z","iopub.status.idle":"2024-09-30T12:21:17.495233Z","shell.execute_reply.started":"2024-09-30T12:21:17.460407Z","shell.execute_reply":"2024-09-30T12:21:17.494172Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Reverse Diffusion","metadata":{}},{"cell_type":"code","source":"def reverse(noised, timestep, encoder_hidden_states, pipeline):\n    current = torch.tensor([timestep], dtype=torch.long, device=noised.device)\n    \n    denoised = pipeline.unet(\n        noised, \n        current, \n        encoder_hidden_states=encoder_hidden_states\n    ).sample\n    \n    return denoised","metadata":{"execution":{"iopub.status.busy":"2024-09-30T12:21:17.496582Z","iopub.execute_input":"2024-09-30T12:21:17.496905Z","iopub.status.idle":"2024-09-30T12:21:17.505681Z","shell.execute_reply.started":"2024-09-30T12:21:17.496841Z","shell.execute_reply":"2024-09-30T12:21:17.504654Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def similarity(original, denoised):\n    norm_original = nn.functional.normalize(original, dim=-1)\n    norm_denoised = nn.functional.normalize(denoised, dim=-1)\n    \n    sim = torch.sum(norm_original * norm_denoised, dim=-1).mean()\n    \n    return sim.item()","metadata":{"execution":{"iopub.status.busy":"2024-09-30T12:24:11.082482Z","iopub.execute_input":"2024-09-30T12:24:11.082845Z","iopub.status.idle":"2024-09-30T12:24:11.088423Z","shell.execute_reply.started":"2024-09-30T12:24:11.082813Z","shell.execute_reply":"2024-09-30T12:24:11.087470Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def classify(image_path, categories):\n    num_timesteps = 25\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n    pipeline = StableDiffusionPipeline.from_pretrained(\n        \"runwayml/stable-diffusion-v1-5\",  \n        torch_dtype=torch.float16\n    ).to(device)\n    \n    noise_scheduler = pipeline.scheduler \n    image = read_image(image_path)\n    preprocessed = preprocess(image, device)\n    latents = convert2latent(preprocessed, pipeline, device)\n\n    total_timesteps = noise_scheduler.config.num_train_timesteps\n    selected_timesteps = torch.linspace(0, total_timesteps - 1, steps=num_timesteps, dtype=torch.long).tolist()\n\n    weights = [1.0 for _ in selected_timesteps]\n    \n    scores = []\n\n    for category in categories:\n        text_prompt = f\"a photo of a {category}\"\n        \n        text_inputs = pipeline.tokenizer(\n            text_prompt,  \n            padding=\"max_length\", \n            max_length=pipeline.tokenizer.model_max_length, \n            truncation=True, \n            return_tensors=\"pt\"\n        ).to(device)\n        \n        with torch.no_grad():\n            text_embeddings = pipeline.text_encoder(**text_inputs).last_hidden_state  \n\n        category_scores = []\n\n        for timestep, weight in zip(selected_timesteps, weights):\n            noisy_latents = forward(latents, timestep, noise_scheduler)\n\n            denoised_latents = reverse(noisy_latents, timestep, text_embeddings, pipeline)\n\n            score = similarity(latents, denoised_latents)  \n            category_scores.append(score * weight)\n\n        total_score = sum(category_scores)\n        scores.append(total_score)\n\n    print(\"Scores: \", scores)\n    predicted = categories[scores.index(min(scores))]\n\n    return predicted","metadata":{"execution":{"iopub.status.busy":"2024-09-30T12:41:44.211224Z","iopub.execute_input":"2024-09-30T12:41:44.211667Z","iopub.status.idle":"2024-09-30T12:41:44.223133Z","shell.execute_reply.started":"2024-09-30T12:41:44.211628Z","shell.execute_reply":"2024-09-30T12:41:44.222188Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"# Test it Out!","metadata":{}},{"cell_type":"code","source":"image_path = \"/kaggle/input/cat-image/cat1.jpg\"  \nclasses = [\"dog\", \"horse\", \"cat\", \"elephant\", \"zebra\", \"leopard\"]\n\nresult = classify(image_path, classes)\nprint(f\"Predicted class: {result}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-30T12:37:15.704832Z","iopub.execute_input":"2024-09-30T12:37:15.705178Z","iopub.status.idle":"2024-09-30T12:37:42.863293Z","shell.execute_reply.started":"2024-09-30T12:37:15.705135Z","shell.execute_reply":"2024-09-30T12:37:42.862142Z"},"trusted":true},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56a41ba9e98149419d5634a2f8880427"}},"metadata":{}},{"name":"stdout","text":"Scores:  [4.23095703125, 4.239837646484375, 4.059783935546875, 4.257659912109375, 4.17352294921875, 4.104644775390625]\nPredicted class: cat\n","output_type":"stream"}]},{"cell_type":"code","source":"image_path = \"/kaggle/input/classify-diffusion/car1.jpeg\"  \nclasses = [\"car\", \"truck\", \"bus\"]\n\nresult = classify(image_path, classes)\nprint(f\"Predicted class: {result}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-30T12:37:42.864601Z","iopub.execute_input":"2024-09-30T12:37:42.864902Z","iopub.status.idle":"2024-09-30T12:37:58.018709Z","shell.execute_reply.started":"2024-09-30T12:37:42.864872Z","shell.execute_reply":"2024-09-30T12:37:58.017694Z"},"trusted":true},"execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c2ea906a84e4565adc51e98bd41dd8a"}},"metadata":{}},{"name":"stdout","text":"Scores:  [5.257720947265625, 5.314910888671875, 5.29034423828125]\nPredicted class: car\n","output_type":"stream"}]},{"cell_type":"code","source":"image_path = \"/kaggle/input/classify-diffusion/bird1.jpeg\"  \nclasses = [\"bird\", \"human\", \"fish\", \"insect\"]\n\nresult = classify(image_path, classes)\nprint(f\"Predicted class: {result}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-30T12:37:58.021245Z","iopub.execute_input":"2024-09-30T12:37:58.021651Z","iopub.status.idle":"2024-09-30T12:38:17.227019Z","shell.execute_reply.started":"2024-09-30T12:37:58.021608Z","shell.execute_reply":"2024-09-30T12:38:17.225947Z"},"trusted":true},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f61f1249d4649c08e455dc70ef57704"}},"metadata":{}},{"name":"stdout","text":"Scores:  [2.466888427734375, 2.476470947265625, 2.480499267578125, 2.487457275390625]\nPredicted class: bird\n","output_type":"stream"}]}]}