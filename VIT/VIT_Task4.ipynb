{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":840806,"sourceType":"datasetVersion","datasetId":59760},{"sourceId":9511667,"sourceType":"datasetVersion","datasetId":5789857},{"sourceId":9511786,"sourceType":"datasetVersion","datasetId":5789961},{"sourceId":9511795,"sourceType":"datasetVersion","datasetId":5789970},{"sourceId":9511807,"sourceType":"datasetVersion","datasetId":5789976},{"sourceId":9511810,"sourceType":"datasetVersion","datasetId":5789979}],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Task 4: Inductive Biases of Models: Semantic Biases\n# ","metadata":{}},{"cell_type":"code","source":"import timm\nimport torch\nimport torch.nn as nn\n\nclass ViTClassifier(nn.Module):\n    def __init__(self, num_classes, pretrained=True, finetune=\"classifier\"):\n        super(ViTClassifier, self).__init__()\n        self.vit = timm.create_model('vit_base_patch16_224', pretrained=pretrained)\n        self.vit.head = nn.Linear(self.vit.head.in_features, num_classes)\n\n        if finetune == \"classifier\":\n            # Freezing the backbone\n            for param in self.vit.parameters():\n                param.requires_grad = False\n            # Unfreezing the classifier\n            for param in self.vit.head.parameters():\n                param.requires_grad = True\n\n    def forward(self, x):\n        return self.vit(x)\n\ndef load_vit_model(num_classes, device):\n    model = ViTClassifier(num_classes)\n    model = model.to(device)\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-09-29T22:52:23.410163Z","iopub.execute_input":"2024-09-29T22:52:23.410553Z","iopub.status.idle":"2024-09-29T22:52:29.673483Z","shell.execute_reply.started":"2024-09-29T22:52:23.410501Z","shell.execute_reply":"2024-09-29T22:52:29.672684Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nfrom PIL import Image\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\n\nIMAGE_SIZE = 224\nTRAIN_TFMS = transforms.Compose([\n    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n])\n\nTEST_TFMS = transforms.Compose([\n    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n    transforms.ToTensor(),\n])\n\nclass Animal10Dataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.image_paths = []\n        self.labels = []\n        self.class_to_idx = {label: idx for idx, label in enumerate(os.listdir(root_dir))}\n        \n        for label in os.listdir(root_dir):\n            label_dir = os.path.join(root_dir, label)\n            if os.path.isdir(label_dir):\n                for img_file in os.listdir(label_dir):\n                    img_path = os.path.join(label_dir, img_file)\n                    self.image_paths.append(img_path)\n                    self.labels.append(self.class_to_idx[label])  \n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        \n        try:\n            image = Image.open(img_path).convert('RGB')\n        except (OSError, FileNotFoundError):\n            print(f\"Skipping invalid image: {img_path}\")\n            return self.__getitem__((idx + 1) % len(self.image_paths))  \n\n        label = self.labels[idx]\n        if self.transform:\n            image = self.transform(image)\n\n        return image, torch.tensor(label) \n\n# Function to get DataLoader\ndef get_dataloader(root_dir, batch_size=32, num_workers=1):\n    \"\"\"Load the Animal10 dataset and return train and test DataLoader.\"\"\"\n    train_dataset = Animal10Dataset(os.path.join(root_dir, 'raw-img'), transform=TRAIN_TFMS)\n    test_dataset = Animal10Dataset(os.path.join(root_dir, 'raw-img'), transform=TEST_TFMS)\n\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n\n    return train_loader, test_loader\n","metadata":{"execution":{"iopub.status.busy":"2024-09-29T23:02:44.883248Z","iopub.execute_input":"2024-09-29T23:02:44.884175Z","iopub.status.idle":"2024-09-29T23:02:44.898221Z","shell.execute_reply.started":"2024-09-29T23:02:44.884134Z","shell.execute_reply":"2024-09-29T23:02:44.897371Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom timm import create_model\nfrom torch.utils.data import DataLoader\nfrom torch.cuda.amp import autocast, GradScaler \n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ndef fine_tune_vit(num_epochs=3, learning_rate=1e-4, batch_size=32, root_dir='/kaggle/input/animals10'):\n    \"\"\"Fine-tune a pre-trained ViT model on the Animal10 dataset.\"\"\"\n    \n    train_loader, test_loader = get_dataloader(root_dir=root_dir, batch_size=batch_size)\n    model = ViTClassifier(num_classes=10) \n    model = model.to(device)\n    \n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n    scaler = GradScaler()\n\n    model.train()\n    for epoch in range(num_epochs):\n        running_loss = 0.0\n        for i, (inputs, labels) in enumerate(train_loader):\n            inputs, labels = inputs.to(device), labels.to(device)\n            \n            optimizer.zero_grad()\n\n            with autocast():\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n            \n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n\n            running_loss += loss.item()\n            if i % 100 == 99:  \n                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {running_loss / 100:.4f}')\n                running_loss = 0.0\n\n    torch.save(model.state_dict(), 'fine_tuned_vit_animal10.pth')\n    print(\"Model fine-tuned and saved successfully.\")\n\nfine_tune_vit(num_epochs=3, batch_size=64, root_dir='/kaggle/input/animals10')  # Adjust batch size as needed\n","metadata":{"execution":{"iopub.status.busy":"2024-09-29T22:52:29.691614Z","iopub.execute_input":"2024-09-29T22:52:29.692269Z","iopub.status.idle":"2024-09-29T23:00:49.355060Z","shell.execute_reply.started":"2024-09-29T22:52:29.692224Z","shell.execute_reply":"2024-09-29T23:00:49.353882Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5caa5442ff084abd98c1394430e69af9"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_30/753319193.py:26: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler()\n/tmp/ipykernel_30/753319193.py:39: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/3], Step [100/410], Loss: 1.3425\nEpoch [1/3], Step [200/410], Loss: 0.4062\nEpoch [1/3], Step [300/410], Loss: 0.2227\nEpoch [1/3], Step [400/410], Loss: 0.1561\nEpoch [2/3], Step [100/410], Loss: 0.1151\nEpoch [2/3], Step [200/410], Loss: 0.0909\nEpoch [2/3], Step [300/410], Loss: 0.0867\nEpoch [2/3], Step [400/410], Loss: 0.0732\nEpoch [3/3], Step [100/410], Loss: 0.0662\nEpoch [3/3], Step [200/410], Loss: 0.0655\nEpoch [3/3], Step [300/410], Loss: 0.0591\nEpoch [3/3], Step [400/410], Loss: 0.0601\nModel fine-tuned and saved successfully.\n","output_type":"stream"}]},{"cell_type":"code","source":"import shutil\nshutil.make_archive(\"finetune-animals10\", 'zip', \"/kaggle/working/fine_tuned_vit_animal10\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom tqdm import tqdm\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ndef inference_vit(batch_size=32, dataset_dir='/kaggle/input/animals10'):\n    \"\"\"Run inference on the provided dataset using the fine-tuned ViT model.\"\"\"\n\n    _, test_loader = get_dataloader(root_dir=dataset_dir, batch_size=batch_size)\n\n    model = ViTClassifier(num_classes=10) \n    model.load_state_dict(torch.load('fine_tuned_vit_animal10.pth'))  \n    model = model.to(device)\n    model.eval()\n\n    correct = 0\n    total = 0\n    predictions = []\n\n    with torch.no_grad():\n        for inputs, labels in tqdm(test_loader, desc=\"Running Inference\", unit=\"batch\"):\n            inputs = inputs.to(device)\n            labels = labels.to(device)  \n            \n            outputs = model(inputs)\n            _, predicted = torch.max(outputs.data, 1)\n            predictions.extend(zip(labels.cpu().numpy(), predicted.cpu().numpy()))\n\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    accuracy = 100 * correct / total if total > 0 else 0\n    print(f'Test Accuracy: {accuracy:.2f}%')\n\nprint(\"\\nInference on Full Animals dataset:\")\ninference_vit(batch_size=32, dataset_dir='/kaggle/input/animals10')  \n","metadata":{"execution":{"iopub.status.busy":"2024-09-29T23:04:05.159694Z","iopub.execute_input":"2024-09-29T23:04:05.160089Z","iopub.status.idle":"2024-09-29T23:06:51.636704Z","shell.execute_reply.started":"2024-09-29T23:04:05.160037Z","shell.execute_reply":"2024-09-29T23:06:51.635598Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"\nInference on Full Animals dataset:\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_30/1305658164.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load('fine_tuned_vit_animal10.pth'))  # Load fine-tuned weights\nRunning Inference: 100%|██████████| 819/819 [02:44<00:00,  4.98batch/s]","output_type":"stream"},{"name":"stdout","text":"Test Accuracy: 98.87%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"INFERENCE ON SUBSET MAIN DATA","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nfrom tqdm import tqdm \nfrom PIL import Image\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Custom Dataset for loading images\nclass CustomDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.images = []\n        self.labels = []\n        self.class_to_idx = {name: idx for idx, name in enumerate(os.listdir(root_dir))}\n        \n        for label in os.listdir(root_dir):\n            label_dir = os.path.join(root_dir, label)\n            if os.path.isdir(label_dir):\n                for img_file in os.listdir(label_dir):\n                    img_path = os.path.join(label_dir, img_file)\n                    self.images.append(img_path)\n                    self.labels.append(self.class_to_idx[label]) \n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        img_path = self.images[idx]\n        image = Image.open(img_path).convert(\"RGB\")\n\n        if self.transform:\n            image = self.transform(image)\n\n        label = self.labels[idx]\n        return image, label\n\ndef get_transform():\n    return transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n    ])\n\ndef get_dataloader(root_dir, batch_size):\n    dataset = CustomDataset(root_dir=root_dir, transform=get_transform())\n    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n    return dataloader\n\ndef inference_vit(model, dataset_dir, batch_size=32):\n    \"\"\"Run inference on the provided dataset using the fine-tuned ViT model.\"\"\"\n    \n    test_loader = get_dataloader(root_dir=dataset_dir, batch_size=batch_size)\n    model.eval()\n\n    correct = 0\n    total = 0\n    predictions = []\n\n    with torch.no_grad():\n        for inputs, labels in tqdm(test_loader, desc=\"Running Inference\", unit=\"batch\"):\n            inputs = inputs.to(device)\n            labels = labels.to(device)  \n            \n            outputs = model(inputs)\n            _, predicted = torch.max(outputs.data, 1)\n\n            predictions.extend(zip(labels.cpu().numpy(), predicted.cpu().numpy()))\n\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    accuracy = 100 * correct / total if total > 0 else 0\n    print(f'Test Accuracy: {accuracy:.2f}%')\n\ndef run_inference_on_dataset(model_path, dataset_dir, batch_size=32):\n    model = ViTClassifier(num_classes=10)\n    model.load_state_dict(torch.load(model_path))  \n    model = model.to(device)\n    \n    print(\"\\nRunning inference...\")\n    inference_vit(model, dataset_dir=dataset_dir, batch_size=batch_size)\n\n\nmodel_path = 'fine_tuned_vit_animal10.pth'\ndataset_dir = '/kaggle/input/animals-base-shape/val 2'\nrun_inference_on_dataset(model_path, dataset_dir, batch_size=32)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-29T23:10:57.994838Z","iopub.execute_input":"2024-09-29T23:10:57.995335Z","iopub.status.idle":"2024-09-29T23:11:09.654299Z","shell.execute_reply.started":"2024-09-29T23:10:57.995294Z","shell.execute_reply":"2024-09-29T23:11:09.653311Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/2959279934.py:95: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(model_path))  # Load fine-tuned weights\n","output_type":"stream"},{"name":"stdout","text":"\nRunning inference...\n","output_type":"stream"},{"name":"stderr","text":"Running Inference: 100%|██████████| 32/32 [00:09<00:00,  3.23batch/s]","output_type":"stream"},{"name":"stdout","text":"Test Accuracy: 99.10%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"new_dataset_dir = '/kaggle/input/canny-animals/Canny_Animals'  # Change this path to your new dataset\nrun_inference_on_dataset(model_path='fine_tuned_vit_animal10.pth', dataset_dir=new_dataset_dir, batch_size=32)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-29T23:17:32.551442Z","iopub.execute_input":"2024-09-29T23:17:32.552284Z","iopub.status.idle":"2024-09-29T23:17:46.825515Z","shell.execute_reply.started":"2024-09-29T23:17:32.552243Z","shell.execute_reply":"2024-09-29T23:17:46.824545Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/2959279934.py:95: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(model_path))  # Load fine-tuned weights\n","output_type":"stream"},{"name":"stdout","text":"\nRunning inference...\n","output_type":"stream"},{"name":"stderr","text":"Running Inference: 100%|██████████| 32/32 [00:12<00:00,  2.59batch/s]","output_type":"stream"},{"name":"stdout","text":"Test Accuracy: 57.00%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"new_dataset_dir = '/kaggle/input/base-animal-style-and-color/small_animal_dataset_updated'  # Change this path to your new dataset\nrun_inference_on_dataset(model_path='fine_tuned_vit_animal10.pth', dataset_dir=new_dataset_dir, batch_size=32)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-29T23:20:19.887044Z","iopub.execute_input":"2024-09-29T23:20:19.887921Z","iopub.status.idle":"2024-09-29T23:20:33.563897Z","shell.execute_reply.started":"2024-09-29T23:20:19.887879Z","shell.execute_reply":"2024-09-29T23:20:33.562942Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/2959279934.py:95: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(model_path))  # Load fine-tuned weights\n","output_type":"stream"},{"name":"stdout","text":"\nRunning inference...\n","output_type":"stream"},{"name":"stderr","text":"Running Inference: 100%|██████████| 31/31 [00:11<00:00,  2.62batch/s]","output_type":"stream"},{"name":"stdout","text":"Test Accuracy: 99.90%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"new_dataset_dir = '/kaggle/input/stylized-animals/Stylized_images'  # Change this path to your new dataset\nrun_inference_on_dataset(model_path='fine_tuned_vit_animal10.pth', dataset_dir=new_dataset_dir, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2024-09-29T23:25:47.318535Z","iopub.execute_input":"2024-09-29T23:25:47.319448Z","iopub.status.idle":"2024-09-29T23:25:52.959248Z","shell.execute_reply.started":"2024-09-29T23:25:47.319395Z","shell.execute_reply":"2024-09-29T23:25:52.958269Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/2959279934.py:95: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(model_path))  # Load fine-tuned weights\n","output_type":"stream"},{"name":"stdout","text":"\nRunning inference...\n","output_type":"stream"},{"name":"stderr","text":"Running Inference: 100%|██████████| 11/11 [00:03<00:00,  2.78batch/s]","output_type":"stream"},{"name":"stdout","text":"Test Accuracy: 16.29%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"new_dataset_dir = '/kaggle/input/grayscale-animals'  # Change this path to your new dataset\nrun_inference_on_dataset(model_path='fine_tuned_vit_animal10.pth', dataset_dir=new_dataset_dir, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2024-09-29T23:26:04.504699Z","iopub.execute_input":"2024-09-29T23:26:04.505543Z","iopub.status.idle":"2024-09-29T23:26:10.603478Z","shell.execute_reply.started":"2024-09-29T23:26:04.505499Z","shell.execute_reply":"2024-09-29T23:26:10.602597Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/2959279934.py:95: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(model_path))  # Load fine-tuned weights\n","output_type":"stream"},{"name":"stdout","text":"\nRunning inference...\n","output_type":"stream"},{"name":"stderr","text":"Running Inference: 100%|██████████| 16/16 [00:04<00:00,  3.63batch/s]","output_type":"stream"},{"name":"stdout","text":"Test Accuracy: 99.60%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]}]}