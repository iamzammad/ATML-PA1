{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3032274,"sourceType":"datasetVersion","datasetId":1856924},{"sourceId":9514389,"sourceType":"datasetVersion","datasetId":5791941},{"sourceId":9514628,"sourceType":"datasetVersion","datasetId":5792138},{"sourceId":9514655,"sourceType":"datasetVersion","datasetId":5792162},{"sourceId":9514691,"sourceType":"datasetVersion","datasetId":5792193}],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Task 5: Inductive Biases of Models: Locality Biases","metadata":{}},{"cell_type":"code","source":"%%writefile VIT_Model.py\nimport timm\nimport torch\nimport torch.nn as nn\n\n\nclass ViTClassifier(nn.Module):\n    def __init__(self, num_classes, pretrained=True, finetune=\"classifier\"):\n        super(ViTClassifier, self).__init__()\n        self.vit = timm.create_model('vit_base_patch16_224', pretrained=pretrained)\n        self.vit.head = nn.Linear(self.vit.head.in_features, num_classes)\n\n        if finetune == \"classifier\":\n            #freezing the backbone\n            for param in self.vit.parameters():\n                param.requires_grad = False\n            #unfreezing the classifier\n            for param in self.vit.head.parameters():\n                param.requires_grad = True\n\n    def forward(self, x):\n        return self.vit(x)\n\ndef load_vit_model(num_classes, device):\n    model = ViTClassifier(num_classes)\n    model = model.to(device)\n    return model\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-30T08:46:10.872057Z","iopub.execute_input":"2024-09-30T08:46:10.872464Z","iopub.status.idle":"2024-09-30T08:46:10.879073Z","shell.execute_reply.started":"2024-09-30T08:46:10.872424Z","shell.execute_reply":"2024-09-30T08:46:10.878171Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Writing VIT_Model.py\n","output_type":"stream"}]},{"cell_type":"code","source":"%%writefile data.py\n\nimport os\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import datasets, transforms\nfrom PIL import Image\n\nclass CustomCIFAR10Dataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.classes = sorted(os.listdir(self.root_dir)) \n        self.image_paths = []\n        self.labels = []\n        \n        for idx, class_name in enumerate(self.classes):\n            class_dir = os.path.join(self.root_dir, class_name)\n            if os.path.isdir(class_dir):\n                for img_file in os.listdir(class_dir):\n                    img_path = os.path.join(class_dir, img_file)\n                    self.image_paths.append(img_path)\n                    self.labels.append(idx)\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        label = self.labels[idx]\n        image = Image.open(img_path).convert(\"RGB\")\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label\n\ndef get_data_loaders(batch_size, root_dir, img_size=224, num_workers=2):\n    # Define transforms for train and validation datasets\n    transform = transforms.Compose([\n        transforms.Resize((img_size, img_size)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n\n    train_dataset = CustomCIFAR10Dataset(root_dir=os.path.join(root_dir, 'train'), transform=transform)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n\n    test_dataset = CustomCIFAR10Dataset(root_dir=os.path.join(root_dir, 'test'), transform=transform)\n    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n\n    return train_loader, test_loader\n\ndef load_data(batch_size, root_dir, img_size=224, num_workers=2):\n    train_loader, test_loader = get_data_loaders(batch_size=batch_size, root_dir=root_dir, img_size=img_size, num_workers=num_workers)\n    return train_loader, test_loader\n","metadata":{"execution":{"iopub.status.busy":"2024-09-30T08:46:13.398083Z","iopub.execute_input":"2024-09-30T08:46:13.398977Z","iopub.status.idle":"2024-09-30T08:46:13.405544Z","shell.execute_reply.started":"2024-09-30T08:46:13.398935Z","shell.execute_reply":"2024-09-30T08:46:13.404637Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Writing data.py\n","output_type":"stream"}]},{"cell_type":"code","source":"%%writefile Fine_Tune.py\n\nimport torch\nimport torch.optim as optim\nimport torch.nn as nn\nfrom VIT_Model import load_vit_model\nfrom data import load_data\n\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nnum_classes = 10\nbatch_size = 64\nlearning_rate = 1e-4\nnum_epochs = 3\n\nroot_dir = \"/kaggle/input/cifar10/cifar10\"\ntrain_loader, test_loader = load_data(batch_size=batch_size, root_dir=root_dir)\n\nmodel = load_vit_model(num_classes, device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\ndef train_model(model, train_loader, criterion, optimizer, device, num_epochs):\n    model.train()\n    for epoch in range(num_epochs):\n        running_loss = 0.0\n        for i, (images, labels) in enumerate(train_loader):\n            images, labels = images.to(device), labels.to(device)\n\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n            if (i + 1) % 100 == 0:\n                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n\n        print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {running_loss/len(train_loader):.4f}')\n\n    torch.save(model.state_dict(), 'fine_tuned_vit_cifar10.pth')\n    print(\"Model fine-tuned and saved successfully.\")\n\ndef evaluate_model(model, test_loader, device):\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    accuracy = 100 * correct / total\n    print(f'Test Accuracy: {accuracy:.2f}%')\n\ntrain_model(model, train_loader, criterion, optimizer, device, num_epochs)\nevaluate_model(model, test_loader, device)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-30T08:46:16.561037Z","iopub.execute_input":"2024-09-30T08:46:16.561459Z","iopub.status.idle":"2024-09-30T08:46:16.569864Z","shell.execute_reply.started":"2024-09-30T08:46:16.561419Z","shell.execute_reply":"2024-09-30T08:46:16.568794Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Writing Fine_Tune.py\n","output_type":"stream"}]},{"cell_type":"code","source":"!python Fine_Tune.py","metadata":{"execution":{"iopub.status.busy":"2024-09-30T08:46:20.134562Z","iopub.execute_input":"2024-09-30T08:46:20.134948Z","iopub.status.idle":"2024-09-30T09:03:09.162607Z","shell.execute_reply.started":"2024-09-30T08:46:20.134910Z","shell.execute_reply":"2024-09-30T09:03:09.161622Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"model.safetensors: 100%|██████████████████████| 346M/346M [00:00<00:00, 383MB/s]\nEpoch [1/3], Step [100/782], Loss: 0.8708\nEpoch [1/3], Step [200/782], Loss: 0.5909\nEpoch [1/3], Step [300/782], Loss: 0.5100\nEpoch [1/3], Step [400/782], Loss: 0.4517\nEpoch [1/3], Step [500/782], Loss: 0.2669\nEpoch [1/3], Step [600/782], Loss: 0.1764\nEpoch [1/3], Step [700/782], Loss: 0.3157\nEpoch [1/3], Average Loss: 0.5273\nEpoch [2/3], Step [100/782], Loss: 0.2288\nEpoch [2/3], Step [200/782], Loss: 0.1261\nEpoch [2/3], Step [300/782], Loss: 0.1179\nEpoch [2/3], Step [400/782], Loss: 0.1835\nEpoch [2/3], Step [500/782], Loss: 0.1851\nEpoch [2/3], Step [600/782], Loss: 0.2977\nEpoch [2/3], Step [700/782], Loss: 0.3492\nEpoch [2/3], Average Loss: 0.2039\nEpoch [3/3], Step [100/782], Loss: 0.1132\nEpoch [3/3], Step [200/782], Loss: 0.2189\nEpoch [3/3], Step [300/782], Loss: 0.1418\nEpoch [3/3], Step [400/782], Loss: 0.1791\nEpoch [3/3], Step [500/782], Loss: 0.1451\nEpoch [3/3], Step [600/782], Loss: 0.2028\nEpoch [3/3], Step [700/782], Loss: 0.1623\nEpoch [3/3], Average Loss: 0.1719\nModel fine-tuned and saved successfully.\nTest Accuracy: 94.33%\n","output_type":"stream"}]},{"cell_type":"code","source":"import shutil\nshutil.make_archive(\"finetune-cifar10\", 'zip', \"/kaggle/working/fine_tuned_vit_cifar10\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-30T08:41:02.279779Z","iopub.execute_input":"2024-09-30T08:41:02.280519Z","iopub.status.idle":"2024-09-30T08:41:02.288886Z","shell.execute_reply.started":"2024-09-30T08:41:02.280461Z","shell.execute_reply":"2024-09-30T08:41:02.288016Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/finetune-cifar10.zip'"},"metadata":{}}]},{"cell_type":"code","source":"%%writefile data.py\nimport os\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\n\nclass BaseDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.image_paths = []\n        self.labels = []\n\n        self.classes = sorted(os.listdir(self.root_dir))  \n\n        for idx, class_name in enumerate(self.classes):\n            class_dir = os.path.join(self.root_dir, class_name)\n            if os.path.isdir(class_dir):\n                for img_file in os.listdir(class_dir):\n                    img_path = os.path.join(class_dir, img_file)\n                    self.image_paths.append(img_path)\n                    self.labels.append(idx)\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        label = self.labels[idx]\n        image = Image.open(img_path).convert(\"RGB\")\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label\n\ndef get_data_loader(dataset_class, root_dir, batch_size=64, img_size=224, num_workers=2):\n    transform = transforms.Compose([\n        transforms.Resize((img_size, img_size)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n    \n    dataset = dataset_class(root_dir=root_dir, transform=transform)\n    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n    \n    return loader\n\nclass NoisyCIFAR10Dataset(BaseDataset):\n    pass\n","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:04:03.548317Z","iopub.execute_input":"2024-09-30T09:04:03.549228Z","iopub.status.idle":"2024-09-30T09:04:03.555810Z","shell.execute_reply.started":"2024-09-30T09:04:03.549186Z","shell.execute_reply":"2024-09-30T09:04:03.554935Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Overwriting data.py\n","output_type":"stream"}]},{"cell_type":"code","source":"%%writefile inference.py\nimport torch\nfrom VIT_Model import load_vit_model\nfrom data import get_data_loader, NoisyCIFAR10Dataset\n\ndef run_inference_on_dataset(model_path, dataset_class, root_dir, num_classes=10, batch_size=64, img_size=224, device=None):\n    if device is None:\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n    model = load_vit_model(num_classes, device)\n    model.load_state_dict(torch.load(model_path, map_location=device))\n    print(\"Fine-tuned model loaded successfully.\")\n    loader = get_data_loader(dataset_class, root_dir=root_dir, batch_size=batch_size, img_size=img_size)\n\n    model.eval()\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for images, labels in loader:\n            images, labels = images.to(device), labels.to(device)\n\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    accuracy = 100 * correct / total\n    print(f'Accuracy on dataset \"{root_dir}\": {accuracy:.2f}%')\n\ndef main(model_path, root_dir, dataset_class=NoisyCIFAR10Dataset):\n    run_inference_on_dataset(model_path, dataset_class, root_dir)\n\nif __name__ == \"__main__\":\n    model_path = '/kaggle/working/fine_tuned_vit_cifar10.pth'\n    root_dir = '/kaggle/input/cifar-noise-images'\n    main(model_path, root_dir)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:06:10.425498Z","iopub.execute_input":"2024-09-30T09:06:10.426401Z","iopub.status.idle":"2024-09-30T09:06:10.433888Z","shell.execute_reply.started":"2024-09-30T09:06:10.426350Z","shell.execute_reply":"2024-09-30T09:06:10.432962Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Overwriting inference.py\n","output_type":"stream"}]},{"cell_type":"code","source":"# !python inference.py\nfrom inference import main, NoisyCIFAR10Dataset\n\nmodel_path = '/kaggle/working/fine_tuned_vit_cifar10.pth'\nroot_dir = '/kaggle/input/cifarbasesubset/Cifar_Basedataset'\n\n# inference\nmain(model_path, root_dir, NoisyCIFAR10Dataset)","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:06:14.312549Z","iopub.execute_input":"2024-09-30T09:06:14.312959Z","iopub.status.idle":"2024-09-30T09:06:23.518273Z","shell.execute_reply.started":"2024-09-30T09:06:14.312921Z","shell.execute_reply":"2024-09-30T09:06:23.516833Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/kaggle/working/inference.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(model_path, map_location=device))\n","output_type":"stream"},{"name":"stdout","text":"Fine-tuned model loaded successfully.\nAccuracy on dataset \"/kaggle/input/cifarbasesubset/Cifar_Basedataset\": 95.40%\n","output_type":"stream"}]},{"cell_type":"code","source":"# !python inference.py\nfrom inference import main, NoisyCIFAR10Dataset\n\nmodel_path = '/kaggle/working/fine_tuned_vit_cifar10.pth'\nroot_dir = '/kaggle/input/cifarnoisyy/CifarNoisy'\n\n# inference\nmain(model_path, root_dir, NoisyCIFAR10Dataset)","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:19:30.053998Z","iopub.execute_input":"2024-09-30T09:19:30.054444Z","iopub.status.idle":"2024-09-30T09:19:42.521465Z","shell.execute_reply.started":"2024-09-30T09:19:30.054402Z","shell.execute_reply":"2024-09-30T09:19:42.520280Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Fine-tuned model loaded successfully.\nAccuracy on dataset \"/kaggle/input/cifarnoisyy/CifarNoisy\": 85.55%\n","output_type":"stream"}]},{"cell_type":"code","source":"# !python inference.py\nfrom inference import main, NoisyCIFAR10Dataset\n\nmodel_path = '/kaggle/working/fine_tuned_vit_cifar10.pth'\nroot_dir = '/kaggle/input/cifarscrambled/Cifar_Scrambled'\n\n# inference\nmain(model_path, root_dir, NoisyCIFAR10Dataset)","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:10:46.260820Z","iopub.execute_input":"2024-09-30T09:10:46.261292Z","iopub.status.idle":"2024-09-30T09:10:51.512912Z","shell.execute_reply.started":"2024-09-30T09:10:46.261250Z","shell.execute_reply":"2024-09-30T09:10:51.511701Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Fine-tuned model loaded successfully.\nAccuracy on dataset \"/kaggle/input/cifarscrambled/Cifar_Scrambled\": 50.60%\n","output_type":"stream"}]},{"cell_type":"code","source":"# !python inference.py\nfrom inference import main, NoisyCIFAR10Dataset\n\nmodel_path = '/kaggle/working/fine_tuned_vit_cifar10.pth'\nroot_dir = '/kaggle/input/cifarstylized/Cifar_StylizedImages'\n\n# inference\nmain(model_path, root_dir, NoisyCIFAR10Dataset)","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:14:21.298772Z","iopub.execute_input":"2024-09-30T09:14:21.299275Z","iopub.status.idle":"2024-09-30T09:14:26.992738Z","shell.execute_reply.started":"2024-09-30T09:14:21.299235Z","shell.execute_reply":"2024-09-30T09:14:26.991604Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Fine-tuned model loaded successfully.\nAccuracy on dataset \"/kaggle/input/cifarstylized/Cifar_StylizedImages\": 43.16%\n","output_type":"stream"}]}]}